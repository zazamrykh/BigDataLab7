[DEFAULT]
# Общие настройки
log_level = INFO
random_seed = 42

[DATA]
# Настройки данных
data_url = https://huggingface.co/datasets/openfoodfacts/product-database/resolve/main/food.parquet?download=true
data_dir = data
# Размер выборки для обработки
sample_size = 10000
# Формат данных: parquet или csv
data_format = parquet

[PREPROCESSING]
# Настройки предобработки
# Минимальная доля непустых значений для сохранения признака
min_values_threshold = 0.5
remove_outliers = True
# Z-score для определения выбросов
outlier_threshold = 3

[FEATURES]
# Список признаков для кластеризации
# Используем поля, которые есть непосредственно в схеме данных

# list of target nutrient/feature names we'll try to use or extract
# base nutrient names (we'll try to extract 100g values from nutriments)
nutriment_features = energy-kcal,fat,carbohydrates,proteins,sugars

# and keep also some meta/features present as flat columns
other_features = completeness,nova_group,ecoscore_score,nutriscore_score,ingredients_n,additives_n,scans_n

# standard, minmax, robust
scaling_method = standard

[MODEL]
# Настройки модели кластеризации
algorithm = kmeans
n_clusters = 5
max_iterations = 20
model_path = /app/model/kmeans_model

[SPARK]
# Spark configuration settings
master = local[*]
app_name = FoodProductsClustering
driver_memory = 8g
executor_memory = 8g
executor_cores = 2
num_executors = 2
shuffle_partitions = 100
default_parallelism = 8
serializer = org.apache.spark.serializer.KryoSerializer

[MSSQL]
# Настройки подключения к MS SQL Server
server = ${DB_SERVER}
port = ${DB_PORT}
database = ${DB_NAME}
username = ${DB_USER}
password = ${DB_PASSWORD}
driver = com.microsoft.sqlserver.jdbc.SQLServerDriver

# Настройки таблиц
input_table = food_products
output_table = clustering_results

[DATAMART]
host = datamart
port = 8080

[API]
host = 0.0.0.0
port = 8000
debug = True
reload = False

datamart {
  spark {
    app-name = "FoodDataMart"
    master = "local[*]"
    driver-memory = "12g"
    executor-memory = "4g"
    executor-cores = 2
    num-executors = 2
    shuffle-partitions = 100
    default-parallelism = 8
    serializer = "org.apache.spark.serializer.KryoSerializer"
  }

  data {
    parquet-path = "data/food_50k.parquet"
    sample-size = 10000
    api-port = 8080
  }

  mssql {
    server = ${?DB_SERVER}
    port = ${?DB_PORT}
    database = ${?DB_NAME}
    username = ${?DB_USER}
    password = ${?DB_PASSWORD}
    driver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"

    # Таблицы
    input-table = "food_products"
    output-table = "food_products"
    clustering-results-table = "clustering_results"
    cluster-centers-table = "cluster_centers"
  }

  preprocessing {
    # Минимальная доля непустых значений для сохранения признака
    min-values-threshold = 0.5
    remove-outliers = false
    # Z-score для определения выбросов
    outlier-threshold = 3
  }

  features {
    # Список признаков для кластеризации
    nutriment-features = ["energy-kcal", "fat", "carbohydrates", "proteins", "sugars"]
  }
}
